{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Sanity check: sCCA = 1.0 when using same net twice with same input. --\n",
      "Should be very very close to 1.0: sim=1.0000001192092896 (cxa_dist_type='svcca')\n",
      "Is it close to 1.0? True\n",
      "Should be very very close to 1.0: sim=1.0000001192092896 (cxa_dist_type='pwcca')\n",
      "Is it close to 1.0? True\n",
      "Should be very very close to 1.0: sim=1.0 (cxa_dist_type='lincka')\n",
      "Is it close to 1.0? True\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'opd'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/x4/0xq0brj57xz3dbhbmblypbm00000gr/T/ipykernel_8454/480350153.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[0mcxa_dist_type\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'opd'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdistributions\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mNormal\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0.0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscale\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1.0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msample\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mB\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mDin\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 44\u001B[0;31m \u001B[0msim\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mfloat\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcxa_sim\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmdl1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmdl2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlayer_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdownsample_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miters\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcxa_dist_type\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcxa_dist_type\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     45\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'Should be very very close to 1.0: {sim=} ({cxa_dist_type=})'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'Is it close to 1.0? {approx_equal(sim, 1.0, tolerance=1e-2)}'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/ultimate-utils/ultimate-utils-proj-src/uutils/torch_uu/__init__.py\u001B[0m in \u001B[0;36mcxa_sim\u001B[0;34m(mdl1, mdl2, X, layer_name, downsample_size, iters, cxa_dist_type)\u001B[0m\n\u001B[1;32m   1079\u001B[0m def cxa_sim(mdl1: nn.Module, mdl2: nn.Module, X: Tensor, layer_name: str,\n\u001B[1;32m   1080\u001B[0m              downsample_size: Optional[str] = None, iters: int = 1, cxa_dist_type: str = 'pwcca') -> float:\n\u001B[0;32m-> 1081\u001B[0;31m     \u001B[0mdist\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcxa_dist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmdl1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmdl2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlayer_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdownsample_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miters\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcxa_dist_type\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1082\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0;36m1.0\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mdist\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1083\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/ultimate-utils/ultimate-utils-proj-src/uutils/torch_uu/__init__.py\u001B[0m in \u001B[0;36mcxa_dist\u001B[0;34m(mdl1, mdl2, X, layer_name, downsample_size, iters, cxa_dist_type)\u001B[0m\n\u001B[1;32m   1074\u001B[0m def cxa_dist(mdl1: nn.Module, mdl2: nn.Module, X: Tensor, layer_name: str,\n\u001B[1;32m   1075\u001B[0m              downsample_size: Optional[str] = None, iters: int = 1, cxa_dist_type: str = 'pwcca') -> float:\n\u001B[0;32m-> 1076\u001B[0;31m     \u001B[0mdist\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mfloat\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcxa_dist_general\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmdl1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmdl2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlayer_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdownsample_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miters\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcxa_dist_type\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1077\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdist\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1078\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/ultimate-utils/ultimate-utils-proj-src/uutils/torch_uu/__init__.py\u001B[0m in \u001B[0;36mcxa_dist_general\u001B[0;34m(mdl1, mdl2, X1, X2, layer_name, downsample_size, iters, cxa_dist_type)\u001B[0m\n\u001B[1;32m   1047\u001B[0m     \u001B[0;32mfrom\u001B[0m \u001B[0manatome\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mSimilarityHook\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mDistanceHook\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1048\u001B[0m     \u001B[0;31m# - get distance hooks (to intercept the features)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1049\u001B[0;31m     \u001B[0mhook1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mDistanceHook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmdl1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlayer_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcxa_dist_type\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1050\u001B[0m     \u001B[0mhook2\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mDistanceHook\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmdl2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlayer_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcxa_dist_type\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1051\u001B[0m     \u001B[0mmdl1\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0meval\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/ultimate-anatome/anatome/similarity.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, model, name, cca_distance, force_cpu)\u001B[0m\n\u001B[1;32m    243\u001B[0m     \u001B[0mReturns\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdist\u001B[0m \u001B[0minterval\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    244\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 245\u001B[0;31m     \u001B[0mNote\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    246\u001B[0m         \u001B[0;34m-\u001B[0m  \u001B[0;32mfor\u001B[0m \u001B[0ma\u001B[0m \u001B[0mraw\u001B[0m \u001B[0mrepresentation\u001B[0m \u001B[0mA\u001B[0m \u001B[0mwe\u001B[0m \u001B[0mfirst\u001B[0m \u001B[0msubtract\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mmean\u001B[0m \u001B[0mvalue\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0meach\u001B[0m \u001B[0mcolumn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mthen\u001B[0m \u001B[0mdivide\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    247\u001B[0m     \u001B[0mby\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mFrobenius\u001B[0m \u001B[0mnorm\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mto\u001B[0m \u001B[0mproduce\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mnormalized\u001B[0m \u001B[0mrepresentation\u001B[0m \u001B[0mA\u001B[0m\u001B[0;34m*\u001B[0m \u001B[0;34m,\u001B[0m \u001B[0mused\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mall\u001B[0m \u001B[0mour\u001B[0m \u001B[0mdissimilarity\u001B[0m \u001B[0mcomputation\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'opd'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The similarity of the same network should always be 1.0 on same input.\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import uutils.torch_uu\n",
    "from uutils.torch_uu import cxa_sim, approx_equal\n",
    "from uutils.torch_uu.models import get_named_identity_one_layer_linear_model\n",
    "\n",
    "print('--- Sanity check: sCCA = 1.0 when using same net twice with same input. --')\n",
    "\n",
    "Din: int = 10\n",
    "Dout: int = Din\n",
    "B: int = 2000\n",
    "mdl1: nn.Module = get_named_identity_one_layer_linear_model(D=Din)\n",
    "mdl2: nn.Module = mdl1\n",
    "layer_name = 'fc0'\n",
    "\n",
    "# - ends up comparing two matrices of size [B, Dout], on same data, on same model\n",
    "cxa_dist_type = 'svcca'\n",
    "X: torch.Tensor = torch.distributions.Normal(loc=0.0, scale=1.0).sample((B, Din))\n",
    "sim: float = cxa_sim(mdl1, mdl2, X, layer_name, downsample_size=None, iters=1, cxa_dist_type=cxa_dist_type)\n",
    "print(f'Should be very very close to 1.0: {sim=} ({cxa_dist_type=})')\n",
    "print(f'Is it close to 1.0? {approx_equal(sim, 1.0)}')\n",
    "assert(approx_equal(sim, 1.0)), f'Sim should be close to 1.0 but got {sim=}'\n",
    "\n",
    "cxa_dist_type = 'pwcca'\n",
    "X: torch.Tensor = torch.distributions.Normal(loc=0.0, scale=1.0).sample((B, Din))\n",
    "sim: float = cxa_sim(mdl1, mdl2, X, layer_name, downsample_size=None, iters=1, cxa_dist_type=cxa_dist_type)\n",
    "print(f'Should be very very close to 1.0: {sim=} ({cxa_dist_type=})')\n",
    "print(f'Is it close to 1.0? {approx_equal(sim, 1.0)}')\n",
    "assert(approx_equal(sim, 1.0)), f'Sim should be close to 1.0 but got {sim=}'\n",
    "\n",
    "cxa_dist_type = 'lincka'\n",
    "X: torch.Tensor = torch.distributions.Normal(loc=0.0, scale=1.0).sample((B, Din))\n",
    "sim: float = cxa_sim(mdl1, mdl2, X, layer_name, downsample_size=None, iters=1, cxa_dist_type=cxa_dist_type)\n",
    "print(f'Should be very very close to 1.0: {sim=} ({cxa_dist_type=})')\n",
    "print(f'Is it close to 1.0? {approx_equal(sim, 1.0)}')\n",
    "assert(approx_equal(sim, 1.0)), f'Sim should be close to 1.0 but got {sim=}'\n",
    "\n",
    "cxa_dist_type = 'opd'\n",
    "X: torch.Tensor = torch.distributions.Normal(loc=0.0, scale=1.0).sample((B, Din))\n",
    "sim: float = cxa_sim(mdl1, mdl2, X, layer_name, downsample_size=None, iters=1, cxa_dist_type=cxa_dist_type)\n",
    "print(f'Should be very very close to 1.0: {sim=} ({cxa_dist_type=})')\n",
    "print(f'Is it close to 1.0? {approx_equal(sim, 1.0, tolerance=1e-2)}')\n",
    "assert(approx_equal(sim, 1.0, tolerance=1e-2)), f'Sim should be close to 1.0 but got {sim=}'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reproducing: How many data points: https://github.com/google/svcca/blob/master/tutorials/001_Introduction.ipynb\n",
    "\n",
    "As n increases, the cca sim should decrease until it converges to the true max linear correlation in the data.\n",
    "This is because when D is small it's easy to correlate via Xw, Yw since there are less equations (m data) than unknown (D features).\n",
    "Similarly, the similarity decreases because the more data there is, the more variation has to be captured and thus the less\n",
    "correlation there will be.\n",
    "This is correct because 1/4*E[|| Xw - Yw||^2]^2 is proportional the pearson's correlation (assuming Xw, Yw is standardized).\n",
    "\n",
    "\"\"\"\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import uutils\n",
    "from uutils.torch_uu import cxa_sim, approx_equal\n",
    "from uutils.torch_uu.models import get_named_one_layer_random_linear_model\n",
    "\n",
    "import uutils.plot as uulot\n",
    "\n",
    "print('\\n--- Sanity check: when number of data points B is smaller than D, then it should be trivial to make similiarty 1.0 '\n",
    "      '(even if nets/matrices are different)')\n",
    "B: int = 10\n",
    "Dout: int = 100\n",
    "mdl1: nn.Module = get_named_one_layer_random_linear_model(B, Dout)\n",
    "mdl2: nn.Module = get_named_one_layer_random_linear_model(B, Dout)\n",
    "layer_name = 'fc0'\n",
    "# cxa_dist_type = 'pwcca'\n",
    "cxa_dist_type = 'svcca'\n",
    "\n",
    "# - get sim for B << D e.g. [B=10, D=300] easy to \"fit\", to many degrees of freedom\n",
    "X: torch.Tensor = uutils.torch_uu.get_identity_data(B)\n",
    "# mdl1(X) : [B, Dout] = [B, B] [B, Dout]\n",
    "sim: float = cxa_sim(mdl1, mdl2, X, layer_name, downsample_size=None, iters=1, cxa_dist_type=cxa_dist_type)\n",
    "print(f'Should be very very close to 1.0: {sim=} (since we have many features to match the two Xw1, Yw2).')\n",
    "print(f'Is it close to 1.0? {approx_equal(sim, 1.0)}')\n",
    "assert(approx_equal(sim, 1.0))\n",
    "\n",
    "print('\\n-- Santity: just makes sure that when low data is present sim is high and afterwards (as n->infty) sim (CCA) '\n",
    "      'converges to the \"true\" cca value (eventually)')\n",
    "# data_sizes: list[int] = [10, 25, 50, 100, 200, 500, 1_000, 2_000, 5_000]\n",
    "data_sizes: list[int] = [10, 25, 50, 100, 200, 500, 1_000, 2_000, 5_000, 10_000]\n",
    "# data_sizes: list[int] = [10, 25, 50, 100, 200, 500, 1_000, 2_000, 5_000, 10_000, 50_000, 100_000]\n",
    "# data_sizes: list[int] = [10, 25, 50, 100, 200, 500, 1_000, 2_000, 5_000, 10_000]\n",
    "sims: list[float] = []\n",
    "for b in data_sizes:\n",
    "    X: torch.Tensor = uutils.torch_uu.get_identity_data(b)\n",
    "    mdl1: nn.Module = get_named_one_layer_random_linear_model(b, Dout)\n",
    "    mdl2: nn.Module = get_named_one_layer_random_linear_model(b, Dout)\n",
    "    # print(f'{b=}')\n",
    "    sim: float = cxa_sim(mdl1, mdl2, X, layer_name, downsample_size=None, iters=1, cxa_dist_type=cxa_dist_type)\n",
    "    # print(f'{sim=}')\n",
    "    sims.append(sim)\n",
    "\n",
    "print(f'{sims=}')\n",
    "uulot.plot(x=data_sizes, y=sims, xlabel='number of data points (n)', ylabel='similarity (svcca)', show=True, save_plot=True, plot_filename='ndata_vs_svcca_sim', title='Features (D) vs Sim (SVCCA)', x_hline=Dout, x_hline_label=f'B=D={Dout}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import uutils\n",
    "from uutils.torch_uu import cxa_sim, approx_equal\n",
    "from uutils.torch_uu.models import get_named_one_layer_random_linear_model\n",
    "\n",
    "from uutils.plot import plot, save_to_desktop\n",
    "import uutils.plot as uuplot\n",
    "\n",
    "B: int = 10  # [101, 200, 500, 1000, 2000, 5000, 10000]\n",
    "Din: int = B\n",
    "Dout: int = 300\n",
    "mdl1: nn.Module = get_named_one_layer_random_linear_model(Din, Dout)\n",
    "mdl2: nn.Module = get_named_one_layer_random_linear_model(Din, Dout)\n",
    "layer_name = 'fc0'\n",
    "# cxa_dist_type = 'pwcca'\n",
    "cxa_dist_type = 'svcca'\n",
    "\n",
    "X: torch.Tensor = uutils.torch_uu.get_identity_data(B)\n",
    "sim: float = cxa_sim(mdl1, mdl2, X, layer_name, downsample_size=None, iters=1, cxa_dist_type=cxa_dist_type)\n",
    "print(f'Should be very very close to 1.0: {sim=}')\n",
    "print(f'Is it close to 1.0? {approx_equal(sim, 1.0)}')\n",
    "assert(approx_equal(sim, 1.0))\n",
    "\n",
    "# data_sizes: list[int] = [10, 25, 50, 100, 101, 200, 500, 1_000, 2_000, 5_000, 10_000, 50_000]\n",
    "B: int = 100\n",
    "D_feature_sizes: list[int] = [10, 25, 50, 100, 101, 200, 500, 1_000, 2_000, 5_000, 10_000]\n",
    "sims: list[float] = []\n",
    "for d in D_feature_sizes:\n",
    "    X: torch.Tensor = uutils.torch_uu.get_identity_data(B)\n",
    "    mdl1: nn.Module = get_named_one_layer_random_linear_model(B, d)\n",
    "    mdl2: nn.Module = get_named_one_layer_random_linear_model(B, d)\n",
    "    sim: float = cxa_sim(mdl1, mdl2, X, layer_name, downsample_size=None, iters=1, cxa_dist_type=cxa_dist_type)\n",
    "    # print(f'{d=}, {sim=}')\n",
    "    sims.append(sim)\n",
    "\n",
    "print(f'{sims=}')\n",
    "uuplot.plot(x=D_feature_sizes, y=sims, xlabel='number of features/size of dimension (D)', ylabel='similarity (svcca)', show=True, save_plot=True, plot_filename='D_vs_sim_svcca', title='Features (D) vs Sim (SVCCA)', x_hline=B, x_hline_label=f'B=D={B}')\n",
    "# uuplot.plot(x=D_feature_sizes, y=sims, xlabel='number of features/size of dimension (D)', ylabel='similarity (svcca)', show=True, save_plot=True, plot_filename='D_vs_sim', title='Features (D) vs Sim (SVCCA)')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}